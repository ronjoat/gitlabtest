{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Aulakh_Assignment 5 - NN_from_scratch_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Be48AI2ogQ2",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 5 - Neural Networks Implementation (due: Wed April 15th)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUjYVZjjogQ3",
        "colab_type": "text"
      },
      "source": [
        "This notebook show neural networks implemnetation on the MNIST hand-written dataset.  Adapted from a version published by https://github.com/jdwittenauer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_JWtwz-ogQ4",
        "colab_type": "text"
      },
      "source": [
        "We are going go over the neural network architecture discussed in class. This includes the feed-forward neural network - from input through the hidden layers to the out put and adjusting the weights as to minimize the loss step-by-step through each layer called **backpropagation.**  We'll implement both unregularized and regularized versions of the neural network cost function and gradient computation in the backpropagation function.  We'll also implement random weight initialization and a method to use the network to make predictions.\n",
        "\n",
        "Instead of manually going through gradient descent iterations, we'll simply use a package available for minimizing the backpropogation function.\n",
        "\n",
        "The MNIST data set is available in different sizes and formats from different sources.  We will use the one made avialble here: \"ex3data1.mat\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTWW01hcogQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import loadmat\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYVD55rfogQ-",
        "colab_type": "text"
      },
      "source": [
        "The data we are loading is a dictionary that contains both input data and output.  The input data is a 2D numpy array X contains 5000 grayscale images of handwritten digits of 0, 1, 2, 3, ... 9.  Each raw of 400 entries between 0 and 255 that are grayscale intensity values of 20X20 pixel representation of a handwritten digit that is unrolled into a single vector.\n",
        "\n",
        "The output y contains the corresponding labels of 0,1,2, ..., 9.  \n",
        "\n",
        "Note that in the original convention followed for this dataset: 0 is mapped to 10, while all other labels are exactly the digit they represent.  Unlike in many other programming languages Python entries start at 0 and so we will change 10 back to 0 as it ought to be.\n",
        "\n",
        "**Multiclass classification:** You may notice that in our logistic regression models the output could only be one of two values: 0 or 1.  However what we are attempting here is an example of multiclass classification: outputs of more than two values - 10 in this case.  Neural networks facilitates this easily. In fact what we will allow now is the terminal layer to consist of multiple activations: 10 in this problem.  We use a function called softmax to make the outputs to be probabilties that adds upto 1.  The predicted value will correspond to the activation node with highest probabilty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3EJhtr-ogQ-",
        "colab_type": "text"
      },
      "source": [
        "### Exercise #1: \n",
        "\n",
        "Load the data following the following five cells or by running the 6th cell\n",
        "\n",
        "- you should have the X and y from data in the dataframes X_df and y_df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0swOCnkogQ_",
        "colab_type": "code",
        "outputId": "24f75219-f305-434e-c546-dcc87e7808a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "##This is a dictionary that contains both input data and output.\n",
        "data = loadmat('ex3data1.mat')\n",
        "data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'X': array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
              " '__globals__': [],\n",
              " '__header__': b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Sun Oct 16 13:09:09 2011',\n",
              " '__version__': '1.0',\n",
              " 'y': array([[10],\n",
              "        [10],\n",
              "        [10],\n",
              "        ...,\n",
              "        [ 9],\n",
              "        [ 9],\n",
              "        [ 9]], dtype=uint8)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAuF62YYogRD",
        "colab_type": "code",
        "outputId": "31fd0057-35d6-4ad3-be42-99dfa7c5c45c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data['X'].shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 400)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIR9Rs00ogRG",
        "colab_type": "text"
      },
      "source": [
        "This is the data we will be using through out, let's create some useful variables up-front."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIa6fuVCogRH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data['X']\n",
        "y = data['y']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnYvkIC2ogRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Let us set the values '10' back what it ought to be: 0\n",
        "y[y==10]=0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwGorbw4ogRO",
        "colab_type": "text"
      },
      "source": [
        "#### Let us convert these data sets into dataframes so we can pickle them and move them around without losing integrity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hje1-xQrogRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_df = pd.DataFrame(X)\n",
        "y_df = pd.DataFrame(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UV2e4-StogRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "X_df = pd.read_pickle('X_df.pkl')\n",
        "y_df = pd.read_pickle('y_df.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ltijr1UzogRX",
        "colab_type": "text"
      },
      "source": [
        "### Exercise #2:\n",
        "\n",
        "Display **20** randomly selected images from X_df and display them in two rows by appropriately changing the following code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYc5ajH3ogRX",
        "colab_type": "code",
        "outputId": "691dc06c-d31b-48d3-bac3-af452daa9583",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "#Let us quickly checkout what is in these data sets:\n",
        "sample = np.random.randint(0,len(X), 20)\n",
        "X_samples = [X[i,:] for i in sample]\n",
        "\n",
        "#plot the digits\n",
        "i = 0\n",
        "\n",
        "fig, ax = plt.subplots(nrows=2, ncols=10)\n",
        "for row in ax:\n",
        "    for col in row:\n",
        "        col.imshow(X_samples[i].reshape(20,20))\n",
        "        i += 1\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry-zcAgvogRa",
        "colab_type": "code",
        "outputId": "cf0d67ce-1d6d-4a19-ed68-666cf80bab6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Checkout their labels\n",
        "y[sample].flatten()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 7,  4, 10,  4,  7,  1, 10,  2,  8,  7,  8,  6, 10,  8,  1,  9,  3,\n",
              "        8,  9,  1], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNSMi9K-ogRe",
        "colab_type": "text"
      },
      "source": [
        "**One hot encoding:** Now we need to turn the label array into what is called one-hot-encoded matrix.  The one-hot-matrix is a representation of representation of a n-dimensional vector of values 0, 1, 2, ..., 9 as in here into 10Xn matrix where each column will have all zeros except exactly one 1 in the position corresponding to the value the column represents.  For example 7 will be a column where all entries except the 7th are all zeros and the 7th is a one.\n",
        "\n",
        "One-hot-encoding is a way to represent a vector with binary entries alone."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKjVZgCYogRf",
        "colab_type": "code",
        "outputId": "ccde5c7d-f556-422b-a25c-a4c7e1effe72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "y_onehot = encoder.fit_transform(y)\n",
        "y_onehot.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-gfYA9SogRi",
        "colab_type": "code",
        "outputId": "4dd3f4ee-81c8-46ae-e6e0-559fd3bc92ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Here is an example of an y entry and its one-hot-encoding\n",
        "y[0], y_onehot[0,:]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0], dtype=uint8), array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sda1TRXXogRl",
        "colab_type": "text"
      },
      "source": [
        "The neural network we're going to build for this exercise has an input layer matching the size of our instance data (400 + the bias unit), a hidden layer with 25 units (26 with the bias unit), and an output layer with 10 units corresponding to our one-hot encoding for the class labels. \n",
        "\n",
        "The first piece we need to implement is a cost function to evaluate the loss for a given set of network parameters.  The source mathematical function is in the exercise text (and looks pretty intimidating).  Here are the functions required to compute the cost."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz6E8Yx_ogRl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPejoEe0ogRn",
        "colab_type": "text"
      },
      "source": [
        "## Forward propogation and Cost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqLeZ_-sogRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Forward propogation: This takes us through one sweep from input through one hidden layer to the outputs\n",
        "def forward_propagate(X, theta1, theta2):\n",
        "    m = X.shape[0]\n",
        "    \n",
        "    #First insert a a row of ones into the X data - 0th column\n",
        "    a1 = np.insert(X, 0, values=np.ones(m), axis=1)\n",
        "    \n",
        "    #Caluculate the X*Theta\n",
        "    z2 = a1 * theta1.T\n",
        "    \n",
        "    #now apply the sigmoid function and then insert a column of ones\n",
        "    a2 = np.insert(sigmoid(z2), 0, values=np.ones(m), axis=1)\n",
        "    \n",
        "    #Calculate X*Theta\n",
        "    z3 = a2 * theta2.T\n",
        "    \n",
        "    #The outputs\n",
        "    h = sigmoid(z3)\n",
        "    \n",
        "    #Now return all the calculates values that we need for calculating and then backpropagation\n",
        "    return a1, z2, a2, z3, h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI0ze_NJogRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Cost\n",
        "def cost(params, input_size, hidden_size1, num_labels, X, y, learning_rate):\n",
        "    m = X.shape[0]\n",
        "    X = np.matrix(X)\n",
        "    y = np.matrix(y)\n",
        "    \n",
        "    n1 = hidden_size1 * (input_size + 1)\n",
        "    n2 = n1 + num_labels * (hidden_size1 + 1)\n",
        "    \n",
        "    # reshape the parameter array into parameter matrices for each layer\n",
        "    theta1 = np.matrix(np.reshape(params[:n1], (hidden_size1, (input_size + 1))))\n",
        "    theta2 = np.matrix(np.reshape(params[n1:n2], (num_labels, (hidden_size1 + 1))))\n",
        "\n",
        "    \n",
        "    # run the feed-forward pass\n",
        "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
        "    \n",
        "    # compute the cost\n",
        "    J = 0\n",
        "    for i in range(m):\n",
        "        first_term = - np.multiply(y[i,:], np.log(h[i,:]))\n",
        "        second_term = - (np.multiply((1 - y[i,:]), np.log(1 - h[i,:])))\n",
        "        J += np.sum(first_term + second_term)\n",
        "    \n",
        "    J = J / m\n",
        "    \n",
        "    return J"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rRamDpHogRs",
        "colab_type": "text"
      },
      "source": [
        "We've used the sigmoid function before so that's not new.  The forward-propagate function computes the hypothesis for each training instance given the current parameters.  It's output shape should match the same of our one-hot encoding for y.  We can test this real quick to convince ourselves that it's working as expected (the intermediate steps are also returned as these will be useful later)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_2OowPtogRt",
        "colab_type": "text"
      },
      "source": [
        "### Exercise #3\n",
        "\n",
        "Work the rest of this application (except for exercise 4 later) using hidden_size2 set to 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXK46c9zogRt",
        "colab_type": "code",
        "outputId": "d24dd847-1698-4869-f0d8-c3bdaa26260d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# initial setup\n",
        "input_size = 400\n",
        "hidden_size1 = 25\n",
        "hidden_size2 = 50\n",
        "num_labels = 10\n",
        "learning_rate = 1\n",
        "\n",
        "# randomly initialize a parameter array of the size of the full network's parameters\n",
        "params = (np.random.random(size=hidden_size2 * (input_size + 1) + num_labels * (hidden_size2 + 1)) - 0.5) * 0.25\n",
        "\n",
        "m = X.shape[0]\n",
        "X = np.matrix(X)\n",
        "y = np.matrix(y)\n",
        "\n",
        "# unravel the parameter array into parameter matrices for each layer\n",
        "theta1 = np.matrix(np.reshape(params[:hidden_size2 * (input_size + 1)], (hidden_size2, (input_size + 1))))\n",
        "theta2 = np.matrix(np.reshape(params[hidden_size2 * (input_size + 1):], (num_labels, (hidden_size2 + 1))))\n",
        "\n",
        "theta1.shape, theta2.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50, 401), (10, 51))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bB6omGxogRy",
        "colab_type": "code",
        "outputId": "fd92e83c-37db-4f9e-badf-0a32c3b1c54f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
        "a1.shape, z2.shape, a2.shape, z3.shape, h.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5000, 401), (5000, 50), (5000, 51), (5000, 10), (5000, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppZduzHUogR1",
        "colab_type": "text"
      },
      "source": [
        "The cost function, after computing the hypothesis matrix h, applies the cost equation to compute the total error between y and h."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEeP6hjAogR1",
        "colab_type": "code",
        "outputId": "e3a1daaa-c2b7-421f-d266-6d153e84f990",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cost(params, input_size, hidden_size2, num_labels, X, y_onehot, learning_rate)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.564604243741938"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF6oPNqBogR4",
        "colab_type": "text"
      },
      "source": [
        "## Forward propogation with regularization and Cost\n",
        "\n",
        "Our next step is to add regularization to the cost function.  If you're following along in the exercise text and thought the last equation looked ugly, this one looks REALLY ugly.  It's actually not as complicated as it looks though - in fact, the regularization term is simply an addition to the cost we already computed.  Here's the revised cost function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHg30cL0ogR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cost(params, input_size, hidden_size1, num_labels, X, y, learning_rate):\n",
        "    m = X.shape[0]\n",
        "    X = np.matrix(X)\n",
        "    y = np.matrix(y)\n",
        "    \n",
        "    \n",
        "    n1 = hidden_size1 * (input_size + 1)\n",
        "    n2 = n1 + num_labels * (hidden_size1 + 1)\n",
        "    \n",
        "    # reshape the parameter array into parameter matrices for each layer\n",
        "    theta1 = np.matrix(np.reshape(params[:n1], (hidden_size1, (input_size + 1))))\n",
        "    theta2 = np.matrix(np.reshape(params[n1:n2], (num_labels, (hidden_size1 + 1))))\n",
        "\n",
        "    # run the feed-forward pass\n",
        "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
        "    \n",
        "    # compute the cost\n",
        "    J = 0\n",
        "    for i in range(m):\n",
        "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
        "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
        "        J += np.sum(first_term - second_term)\n",
        "    \n",
        "    J = J / m\n",
        "    \n",
        "    # add the cost regularization term\n",
        "    J += (float(learning_rate) / (2 * m)) * (np.sum(np.power(theta1[:,1:], 2)) + np.sum(np.power(theta2[:,1:], 2)))\n",
        "    \n",
        "    return J"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OupmUjCgogR7",
        "colab_type": "code",
        "outputId": "6afa39d0-e1fc-415b-d086-624a82e6dd41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cost(params, input_size, hidden_size1, num_labels, X, y_onehot, learning_rate)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.2348871357972095"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PM52ERyiogR9",
        "colab_type": "text"
      },
      "source": [
        "Next up is the backpropagation algorithm.  Backpropagation computes the parameter updates that will reduce the error of the network on the training data.  The first thing we need is a function that computes the gradient of the sigmoid function we created earlier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ieXr_5MogR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid_gradient(z):\n",
        "    return np.multiply(sigmoid(z), (1 - sigmoid(z)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaGHGMuBogSB",
        "colab_type": "text"
      },
      "source": [
        "## Backpropogation\n",
        "\n",
        "Now we're ready to implement backpropagation to compute the gradients.  Since the computations required for backpropagation are a superset of those required in the cost function, we're actually going to extend the cost function to also perform backpropagation and return both the cost and the gradients."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME4IGBXqogSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def backprop(params, input_size, hidden_size1, num_labels, X, y, learning_rate):\n",
        "    m = X.shape[0]\n",
        "    X = np.matrix(X)\n",
        "    y = np.matrix(y)\n",
        "    \n",
        "    # reshape the parameter array into parameter matrices for each layer\n",
        "    theta1 = np.matrix(np.reshape(params[:hidden_size1 * (input_size + 1)], (hidden_size1, (input_size + 1))))\n",
        "    theta2 = np.matrix(np.reshape(params[hidden_size1 * (input_size + 1):], (num_labels, (hidden_size1 + 1))))\n",
        "    \n",
        "    # run the feed-forward pass\n",
        "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
        "    \n",
        "    # initializations\n",
        "    J = 0\n",
        "    delta1 = np.zeros(theta1.shape)  # (25, 401)\n",
        "    delta2 = np.zeros(theta2.shape)  # (10, 26)\n",
        "    \n",
        "    # compute the cost\n",
        "    for i in range(m):\n",
        "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
        "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
        "        J += np.sum(first_term - second_term)\n",
        "    \n",
        "    J = J / m\n",
        "    \n",
        "    # add the cost regularization term\n",
        "    J += (float(learning_rate) / (2 * m)) * (np.sum(np.power(theta1[:,1:], 2)) + np.sum(np.power(theta2[:,1:], 2)))\n",
        "    \n",
        "    # perform backpropagation\n",
        "    for t in range(m):\n",
        "        a1t = a1[t,:]  # (1, 401)\n",
        "        z2t = z2[t,:]  # (1, 25)\n",
        "        a2t = a2[t,:]  # (1, 26)\n",
        "        ht = h[t,:]  # (1, 10)\n",
        "        yt = y[t,:]  # (1, 10)\n",
        "        \n",
        "        d3t = ht - yt  # (1, 10)\n",
        "        \n",
        "        #insert a one in first position for bias\n",
        "        z2t = np.insert(z2t, 0, values=np.ones(1))  # (1, 26)\n",
        "        d2t = np.multiply((theta2.T * d3t.T).T, sigmoid_gradient(z2t))  # (1, 26)\n",
        "        \n",
        "        delta1 = delta1 + (d2t[:,1:]).T * a1t\n",
        "        delta2 = delta2 + d3t.T * a2t\n",
        "        \n",
        "    delta1 = delta1 / m\n",
        "    delta2 = delta2 / m\n",
        "    \n",
        "    # unravel the gradient matrices into a single array\n",
        "    grad = np.concatenate((np.ravel(delta1), np.ravel(delta2)))\n",
        "    \n",
        "    return J, grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGaHm_MxogSF",
        "colab_type": "text"
      },
      "source": [
        "The hardest part of the backprop computation (other than understanding WHY we're doing all these calculations) is getting the matrix dimensions right.  By the way, if you find it confusing when to use A * B vs. np.multiply(A, B), you're not alone.  Basically the former is a matrix multiplication and the latter is an element-wise multiplication (unless A or B is a scalar value, in which case it doesn't matter).  I wish there was a more concise syntax for this (maybe there is and I'm just not aware of it).\n",
        "\n",
        "Anyway, let's test it out to make sure the function returns what we're expecting it to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEnTMbNJogSF",
        "colab_type": "code",
        "outputId": "3a276e23-ebe6-42ef-d5cd-e75612fdd6d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "params = (np.random.random(size=hidden_size1 * (input_size + 1) + num_labels * (hidden_size1 + 1)) - 0.5) * 0.25\n",
        "J, grad = backprop(params, input_size, hidden_size1, num_labels, X, y_onehot, learning_rate)\n",
        "J, grad.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7.031192009481413, (10285,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uLf3notogSJ",
        "colab_type": "text"
      },
      "source": [
        "### Exercise 4:\n",
        "\n",
        "1.  Split the datasets X_df and y_onehot into 80% for training and the rest for testing using:\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "2. Then use only the train datasets to train (in the next cell)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSXib9GUwkzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_df, y_onehot, test_size=0.2, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnJOOh3FogSJ",
        "colab_type": "code",
        "outputId": "05c7b74e-4783-47ec-ad6e-000900d11bb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "from scipy.optimize import minimize\n",
        "\n",
        "# minimize the objective function\n",
        "fmin = minimize(fun=backprop, x0=params, args=(input_size, hidden_size1, num_labels, X_train , y_train, learning_rate), \n",
        "                method='TNC', jac=True, options={'maxiter': 250})\n",
        "fmin"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     fun: 0.49743755459069605\n",
              "     jac: array([-1.01735509e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
              "        1.63749480e-04,  1.66067197e-05, -1.97024089e-03])\n",
              " message: 'Converged (|f_n-f_(n-1)| ~= 0)'\n",
              "    nfev: 219\n",
              "     nit: 17\n",
              "  status: 1\n",
              " success: True\n",
              "       x: array([ 0.05365439,  0.10772846,  0.09442987, ..., -0.87720241,\n",
              "       -0.33404702, -0.14082003])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyEAURI8ogSM",
        "colab_type": "text"
      },
      "source": [
        "### Exercise 5:\n",
        "\n",
        "1.  Now use only the test datasets to predict (in the next cell\n",
        "2.  And calclate the accuray by comparing to the test labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNZHoGtOogSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.matrix(X_test)\n",
        "theta1 = np.matrix(np.reshape(fmin.x[:hidden_size1 * (input_size + 1)], (hidden_size1, (input_size + 1))))\n",
        "theta2 = np.matrix(np.reshape(fmin.x[hidden_size1 * (input_size + 1):], (num_labels, (hidden_size1 + 1))))\n",
        "\n",
        "a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
        "y_pred = np.array(np.argmax(h, axis=1))\n",
        "y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGvhCGVwogSP",
        "colab_type": "code",
        "outputId": "dd816c99-4329-444f-dc46-9b3af323dbef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0],\n",
              "        [0],\n",
              "        [0],\n",
              "        ...,\n",
              "        [9],\n",
              "        [9],\n",
              "        [9]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUNixQvcogSS",
        "colab_type": "text"
      },
      "source": [
        "Finally we can compute the accuracy to see how well our trained network is doing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DdKb5ocogST",
        "colab_type": "code",
        "outputId": "0587bbe8-e9cd-4431-93c7-873aebd717a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = [1 if a == b else 0 for (a, b) in zip(y_pred, encoder.inverse_transform(y_test))]\n",
        "accuracy = sum(correct)/len(correct)\n",
        "print('accuracy = {0}%'.format(accuracy * 100))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy = 92.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krgF7gvAogSW",
        "colab_type": "text"
      },
      "source": [
        "### Optional exercise: complete the same train and test parts for the regualrized version of the model below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRcTPtcVogSX",
        "colab_type": "text"
      },
      "source": [
        "### Regularization:\n",
        "\n",
        "We still have one more modification to make to the backprop function - adding regularization to the gradient calculations.  The final regularized version is below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "metSZ3V8ogSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def backprop(params, input_size, hidden_size1, num_labels, X, y, learning_rate):\n",
        "    m = X.shape[0]\n",
        "    X = np.matrix(X)\n",
        "    y = np.matrix(y)\n",
        "    \n",
        "    # reshape the parameter array into parameter matrices for each layer\n",
        "    theta1 = np.matrix(np.reshape(params[:hidden_size1 * (input_size + 1)], (hidden_size1, (input_size + 1))))\n",
        "    theta2 = np.matrix(np.reshape(params[hidden_size1 * (input_size + 1):], (num_labels, (hidden_size1 + 1))))\n",
        "    \n",
        "    # run the feed-forward pass\n",
        "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
        "    \n",
        "    # initializations\n",
        "    J = 0\n",
        "    delta1 = np.zeros(theta1.shape)  # (25, 401)\n",
        "    delta2 = np.zeros(theta2.shape)  # (10, 26)\n",
        "    \n",
        "    # compute the cost\n",
        "    for i in range(m):\n",
        "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
        "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
        "        J += np.sum(first_term - second_term)\n",
        "    \n",
        "    J = J / m\n",
        "    \n",
        "    # add the cost regularization term\n",
        "    J += (float(learning_rate) / (2 * m)) * (np.sum(np.power(theta1[:,1:], 2)) + np.sum(np.power(theta2[:,1:], 2)))\n",
        "    \n",
        "    # perform backpropagation\n",
        "    for t in range(m):\n",
        "        a1t = a1[t,:]  # (1, 401)\n",
        "        z2t = z2[t,:]  # (1, 25)\n",
        "        a2t = a2[t,:]  # (1, 26)\n",
        "        ht = h[t,:]  # (1, 10)\n",
        "        yt = y[t,:]  # (1, 10)\n",
        "        \n",
        "        d3t = ht - yt  # (1, 10)\n",
        "        \n",
        "        z2t = np.insert(z2t, 0, values=np.ones(1))  # (1, 26)\n",
        "        d2t = np.multiply((theta2.T * d3t.T).T, sigmoid_gradient(z2t))  # (1, 26)\n",
        "        \n",
        "        delta1 = delta1 + (d2t[:,1:]).T * a1t\n",
        "        delta2 = delta2 + d3t.T * a2t\n",
        "        \n",
        "    delta1 = delta1 / m\n",
        "    delta2 = delta2 / m\n",
        "    \n",
        "    # add the gradient regularization term\n",
        "    delta1[:,1:] = delta1[:,1:] + (theta1[:,1:] * learning_rate) / m\n",
        "    delta2[:,1:] = delta2[:,1:] + (theta2[:,1:] * learning_rate) / m\n",
        "    \n",
        "    # unravel the gradient matrices into a single array\n",
        "    grad = np.concatenate((np.ravel(delta1), np.ravel(delta2)))\n",
        "    \n",
        "    return J, grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaTaF7wcogSa",
        "colab_type": "code",
        "outputId": "7607c1ec-bdd7-4d8e-e051-0a458a0def30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "J, grad = backprop(params, input_size, hidden_size1, num_labels, X, y_onehot, learning_rate)\n",
        "J, grad.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6.965200853506394, (10285,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXwxaNyfogSd",
        "colab_type": "text"
      },
      "source": [
        "We're finally ready to train our network and use it to make predictions.  This is roughly similar to the previous exercise with multi-class logistic regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwT4Y4Q3ogSe",
        "colab_type": "code",
        "outputId": "2d9bbc99-b974-479b-b030-bda61c63f699",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "from scipy.optimize import minimize\n",
        "\n",
        "# minimize the objective function\n",
        "fmin = minimize(fun=backprop, x0=params, args=(input_size, hidden_size1, num_labels, X, y_onehot, learning_rate), \n",
        "                method='TNC', jac=True, options={'maxiter': 250})\n",
        "fmin"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     fun: 0.7853765531795984\n",
              "     jac: array([ 8.78404888e-03,  7.05897462e-06,  6.88936482e-06, ...,\n",
              "       -1.15480576e-05,  1.01701412e-05, -8.89327163e-06])\n",
              " message: 'Max. number of function evaluations reached'\n",
              "    nfev: 250\n",
              "     nit: 29\n",
              "  status: 3\n",
              " success: False\n",
              "       x: array([-3.55711794,  0.00705897,  0.00688936, ..., -0.23330398,\n",
              "       -0.1976127 , -0.20250271])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1johhJnlogSg",
        "colab_type": "text"
      },
      "source": [
        "We put a bound on the number of iterations since the objective function is not likely to completely converge.  Our total cost has dropped below 0.5 though so that's a good indicator that the algorithm is working.  Let's use the parameters it found and forward-propagate them through the network to get some predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDeyKFxRogSh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.matrix(X)\n",
        "theta1 = np.matrix(np.reshape(fmin.x[:hidden_size1 * (input_size + 1)], (hidden_size1, (input_size + 1))))\n",
        "theta2 = np.matrix(np.reshape(fmin.x[hidden_size1 * (input_size + 1):], (num_labels, (hidden_size1 + 1))))\n",
        "\n",
        "a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
        "y_pred = np.array(np.argmax(h, axis=1))\n",
        "y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSh0fgF-ogSl",
        "colab_type": "text"
      },
      "source": [
        "Finally we can compute the accuracy to see how well our trained network is doing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaSo4u0iogSn",
        "colab_type": "code",
        "outputId": "3decaf70-c7f0-4588-97f1-689e44d27d45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = [1 if a == b else 0 for (a, b) in zip(y_pred, y)]\n",
        "accuracy = sum(correct)/len(correct)\n",
        "print('accuracy = {0}%'.format(accuracy * 100))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy = 96.8%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ECv_mSpogSr",
        "colab_type": "text"
      },
      "source": [
        "And we're done!  We've successfully implemented a rudimentary feed-forward neural network with backpropagation and used it to classify images of handwritten digits.  In the next exercise we'll look at another power supervised learning algorithm, support vector machines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGnH5nbJogSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}